{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01f79eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finsihed loading libs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print('Finsihed loading libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f02d0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finsihed reading data\n"
     ]
    }
   ],
   "source": [
    "orig_x = np.load('X.npy')\n",
    "orig_y = np.load('Y.npy')\n",
    "print('finsihed reading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c76fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2062, 64, 64)\n",
      "(2062, 10)\n",
      "<class 'numpy.ndarray'>\n",
      "Finished reading input data\n",
      "(2062,)\n"
     ]
    }
   ],
   "source": [
    "print(orig_x.shape)\n",
    "print(orig_y.shape)\n",
    "print(type(orig_y))\n",
    "print(\"Finished reading input data\")\n",
    "orig_y = np.argmax(orig_y, axis = 1)\n",
    "print(orig_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd5fd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x228e70dd220>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(orig_x[1751,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcccb0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(2062, 64)\n",
      "(2062,)\n"
     ]
    }
   ],
   "source": [
    "print(type(orig_x))\n",
    "print(type(orig_y))\n",
    "orig_x = orig_x[:,1]\n",
    "print(orig_x.shape)\n",
    "print(orig_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e6d9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2062, 64)\n",
      "(2062, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.DataFrame(orig_x)\n",
    "df_y = pd.DataFrame(orig_y)\n",
    "print(df_x.shape)\n",
    "print(df_y.shape)\n",
    "print(type(df_x))\n",
    "print(type(df_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05b2ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "(2062,)\n",
      "<bound method NDFrame.head of 0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2057    9\n",
      "2058    9\n",
      "2059    9\n",
      "2060    9\n",
      "2061    9\n",
      "Name: 0, Length: 2062, dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_x))\n",
    "print(type(df_y))\n",
    "df_y = df_y.iloc[:,0]\n",
    "print(type(df_y))\n",
    "print(df_y.shape)\n",
    "print(df_y.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae299ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_y[1])\n",
    "print(df_y[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bc1aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(8, 8)\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "oneInst = df_x.iloc[7]\n",
    "print(oneInst.shape)\n",
    "print(type(oneInst))\n",
    "\n",
    "oneInst = oneInst.values.reshape(8,8)\n",
    "print(oneInst.shape)\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.fromarray(oneInst)\n",
    "img.show()\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf04204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a088038",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train\n",
    "x_test = x_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999fc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "print(\"Initialized model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a30768d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finsihed setting the input layer\n"
     ]
    }
   ],
   "source": [
    "model.add(keras.layers.Flatten(input_shape=[8,8]))\n",
    "print('Finsihed setting the input layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f3b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added hidden layer 1\n"
     ]
    }
   ],
   "source": [
    "model.add(keras.layers.Dense( 64, activation='relu'))\n",
    "print(\"Added hidden layer 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d5e1e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added hidden layer 2\n"
     ]
    }
   ],
   "source": [
    "model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "print('Added hidden layer 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60459b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added output layer\n"
     ]
    }
   ],
   "source": [
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "print(\"Added output layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f785d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 8,970\n",
      "Trainable params: 8,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6020b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\", \n",
    "              metrics = ['accuracy'])\n",
    "print(\"Finished compiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f5e03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1649, 64)\n",
      "(1649,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1563bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished categorizing the labels (output)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "print(\"Finished categorizing the labels (output)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b5f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1649, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1340dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input Tensor(\"flatten_input:0\", shape=(None, 8, 8), dtype=float32), but it was called on an input with incompatible shape (None, 64).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input Tensor(\"flatten_input:0\", shape=(None, 8, 8), dtype=float32), but it was called on an input with incompatible shape (None, 64).\n",
      "52/52 [==============================] - 0s 442us/step - loss: 2.3312 - accuracy: 0.1037\n",
      "Epoch 2/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3097 - accuracy: 0.1201\n",
      "Epoch 3/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3048 - accuracy: 0.1079\n",
      "Epoch 4/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.3028 - accuracy: 0.1158\n",
      "Epoch 5/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3021 - accuracy: 0.1098\n",
      "Epoch 6/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3018 - accuracy: 0.1104\n",
      "Epoch 7/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.3015 - accuracy: 0.1225\n",
      "Epoch 8/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3013 - accuracy: 0.1176\n",
      "Epoch 9/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.3011 - accuracy: 0.1189\n",
      "Epoch 10/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3010 - accuracy: 0.1213\n",
      "Epoch 11/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.3010 - accuracy: 0.1225\n",
      "Epoch 12/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.3009 - accuracy: 0.1146\n",
      "Epoch 13/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3008 - accuracy: 0.1170\n",
      "Epoch 14/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.3006 - accuracy: 0.1061\n",
      "Epoch 15/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.3006 - accuracy: 0.1176\n",
      "Epoch 16/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3005 - accuracy: 0.1134\n",
      "Epoch 17/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3004 - accuracy: 0.1049\n",
      "Epoch 18/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3003 - accuracy: 0.1219\n",
      "Epoch 19/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.3003 - accuracy: 0.1116\n",
      "Epoch 20/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.3001 - accuracy: 0.1213\n",
      "Epoch 21/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.3002 - accuracy: 0.1231\n",
      "Epoch 22/500\n",
      "52/52 [==============================] - 0s 442us/step - loss: 2.3002 - accuracy: 0.1140\n",
      "Epoch 23/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2997 - accuracy: 0.1255\n",
      "Epoch 24/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2998 - accuracy: 0.1231\n",
      "Epoch 25/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2999 - accuracy: 0.1267\n",
      "Epoch 26/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2998 - accuracy: 0.1092\n",
      "Epoch 27/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2996 - accuracy: 0.1273\n",
      "Epoch 28/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2995 - accuracy: 0.1195\n",
      "Epoch 29/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2993 - accuracy: 0.1164\n",
      "Epoch 30/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2993 - accuracy: 0.1207\n",
      "Epoch 31/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2993 - accuracy: 0.1164\n",
      "Epoch 32/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2994 - accuracy: 0.1152\n",
      "Epoch 33/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2992 - accuracy: 0.1213\n",
      "Epoch 34/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2991 - accuracy: 0.1201\n",
      "Epoch 35/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2989 - accuracy: 0.1207\n",
      "Epoch 36/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2989 - accuracy: 0.1280\n",
      "Epoch 37/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2989 - accuracy: 0.1189\n",
      "Epoch 38/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2989 - accuracy: 0.1243\n",
      "Epoch 39/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2987 - accuracy: 0.1243\n",
      "Epoch 40/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2987 - accuracy: 0.1219\n",
      "Epoch 41/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2985 - accuracy: 0.1207\n",
      "Epoch 42/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2984 - accuracy: 0.1261\n",
      "Epoch 43/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2984 - accuracy: 0.1219\n",
      "Epoch 44/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2983 - accuracy: 0.1358\n",
      "Epoch 45/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2982 - accuracy: 0.1225\n",
      "Epoch 46/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2981 - accuracy: 0.1334\n",
      "Epoch 47/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2979 - accuracy: 0.1304\n",
      "Epoch 48/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2980 - accuracy: 0.1243\n",
      "Epoch 49/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2978 - accuracy: 0.1352\n",
      "Epoch 50/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2978 - accuracy: 0.1225\n",
      "Epoch 51/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2977 - accuracy: 0.1243\n",
      "Epoch 52/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2977 - accuracy: 0.1304\n",
      "Epoch 53/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2973 - accuracy: 0.1237\n",
      "Epoch 54/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2972 - accuracy: 0.1231\n",
      "Epoch 55/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2972 - accuracy: 0.1243\n",
      "Epoch 56/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2973 - accuracy: 0.1183\n",
      "Epoch 57/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2972 - accuracy: 0.1255\n",
      "Epoch 58/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2972 - accuracy: 0.1255\n",
      "Epoch 59/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2969 - accuracy: 0.1292\n",
      "Epoch 60/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2970 - accuracy: 0.1249\n",
      "Epoch 61/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2969 - accuracy: 0.1273\n",
      "Epoch 62/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2968 - accuracy: 0.1231\n",
      "Epoch 63/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2965 - accuracy: 0.1340\n",
      "Epoch 64/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2964 - accuracy: 0.1298\n",
      "Epoch 65/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2963 - accuracy: 0.1273\n",
      "Epoch 66/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2963 - accuracy: 0.1273\n",
      "Epoch 67/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2962 - accuracy: 0.1322\n",
      "Epoch 68/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2963 - accuracy: 0.1298\n",
      "Epoch 69/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2961 - accuracy: 0.1304\n",
      "Epoch 70/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2960 - accuracy: 0.1231\n",
      "Epoch 71/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2958 - accuracy: 0.1358\n",
      "Epoch 72/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2956 - accuracy: 0.1280\n",
      "Epoch 73/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2957 - accuracy: 0.1273\n",
      "Epoch 74/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2956 - accuracy: 0.1249\n",
      "Epoch 75/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2955 - accuracy: 0.1346\n",
      "Epoch 76/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2954 - accuracy: 0.1261\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 365us/step - loss: 2.2954 - accuracy: 0.1310\n",
      "Epoch 78/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2952 - accuracy: 0.1310\n",
      "Epoch 79/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2953 - accuracy: 0.1292\n",
      "Epoch 80/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2951 - accuracy: 0.1340\n",
      "Epoch 81/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2950 - accuracy: 0.1261\n",
      "Epoch 82/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2948 - accuracy: 0.1255\n",
      "Epoch 83/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2948 - accuracy: 0.1273\n",
      "Epoch 84/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2946 - accuracy: 0.1267\n",
      "Epoch 85/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2946 - accuracy: 0.1255\n",
      "Epoch 86/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2945 - accuracy: 0.1352\n",
      "Epoch 87/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2943 - accuracy: 0.1407\n",
      "Epoch 88/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2942 - accuracy: 0.1261\n",
      "Epoch 89/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2942 - accuracy: 0.1298\n",
      "Epoch 90/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2941 - accuracy: 0.1249\n",
      "Epoch 91/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2940 - accuracy: 0.1286\n",
      "Epoch 92/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2938 - accuracy: 0.1310\n",
      "Epoch 93/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2936 - accuracy: 0.1352\n",
      "Epoch 94/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2934 - accuracy: 0.1371\n",
      "Epoch 95/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2935 - accuracy: 0.1346\n",
      "Epoch 96/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2934 - accuracy: 0.1431\n",
      "Epoch 97/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2933 - accuracy: 0.1377\n",
      "Epoch 98/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2933 - accuracy: 0.1237\n",
      "Epoch 99/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2930 - accuracy: 0.1280\n",
      "Epoch 100/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2929 - accuracy: 0.1298\n",
      "Epoch 101/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2928 - accuracy: 0.1316\n",
      "Epoch 102/500\n",
      "52/52 [==============================] - 0s 558us/step - loss: 2.2928 - accuracy: 0.1304\n",
      "Epoch 103/500\n",
      "52/52 [==============================] - 0s 462us/step - loss: 2.2927 - accuracy: 0.1292\n",
      "Epoch 104/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2925 - accuracy: 0.1280\n",
      "Epoch 105/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2923 - accuracy: 0.1255\n",
      "Epoch 106/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2923 - accuracy: 0.1304\n",
      "Epoch 107/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2922 - accuracy: 0.1364\n",
      "Epoch 108/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2921 - accuracy: 0.1304\n",
      "Epoch 109/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2918 - accuracy: 0.1298\n",
      "Epoch 110/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2919 - accuracy: 0.1316\n",
      "Epoch 111/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2917 - accuracy: 0.1340\n",
      "Epoch 112/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2915 - accuracy: 0.1219\n",
      "Epoch 113/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2913 - accuracy: 0.1273\n",
      "Epoch 114/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2913 - accuracy: 0.1352\n",
      "Epoch 115/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2914 - accuracy: 0.1340\n",
      "Epoch 116/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2912 - accuracy: 0.1280\n",
      "Epoch 117/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2911 - accuracy: 0.1267\n",
      "Epoch 118/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2908 - accuracy: 0.1334\n",
      "Epoch 119/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2907 - accuracy: 0.1322\n",
      "Epoch 120/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2907 - accuracy: 0.1340\n",
      "Epoch 121/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2905 - accuracy: 0.1310\n",
      "Epoch 122/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2904 - accuracy: 0.1334\n",
      "Epoch 123/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2904 - accuracy: 0.1389\n",
      "Epoch 124/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2901 - accuracy: 0.1340\n",
      "Epoch 125/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2899 - accuracy: 0.1352\n",
      "Epoch 126/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2900 - accuracy: 0.1298\n",
      "Epoch 127/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2899 - accuracy: 0.1334\n",
      "Epoch 128/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2897 - accuracy: 0.1237\n",
      "Epoch 129/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2898 - accuracy: 0.1316\n",
      "Epoch 130/500\n",
      "52/52 [==============================] - 0s 442us/step - loss: 2.2894 - accuracy: 0.1267\n",
      "Epoch 131/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2894 - accuracy: 0.1310\n",
      "Epoch 132/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2892 - accuracy: 0.1280\n",
      "Epoch 133/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2890 - accuracy: 0.1310\n",
      "Epoch 134/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2887 - accuracy: 0.1395\n",
      "Epoch 135/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2887 - accuracy: 0.1267\n",
      "Epoch 136/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2888 - accuracy: 0.1425\n",
      "Epoch 137/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2884 - accuracy: 0.1304\n",
      "Epoch 138/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2882 - accuracy: 0.1316\n",
      "Epoch 139/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2883 - accuracy: 0.1267\n",
      "Epoch 140/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2879 - accuracy: 0.1346\n",
      "Epoch 141/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2878 - accuracy: 0.1316\n",
      "Epoch 142/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2879 - accuracy: 0.1334\n",
      "Epoch 143/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2876 - accuracy: 0.1395\n",
      "Epoch 144/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2878 - accuracy: 0.1255\n",
      "Epoch 145/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2873 - accuracy: 0.1334\n",
      "Epoch 146/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2874 - accuracy: 0.1280\n",
      "Epoch 147/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2871 - accuracy: 0.1310\n",
      "Epoch 148/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2870 - accuracy: 0.1255\n",
      "Epoch 149/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2868 - accuracy: 0.1364\n",
      "Epoch 150/500\n",
      "52/52 [==============================] - 0s 442us/step - loss: 2.2866 - accuracy: 0.1286\n",
      "Epoch 151/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2866 - accuracy: 0.1304\n",
      "Epoch 152/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2863 - accuracy: 0.1286\n",
      "Epoch 153/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2862 - accuracy: 0.1316\n",
      "Epoch 154/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2861 - accuracy: 0.1316\n",
      "Epoch 155/500\n",
      "52/52 [==============================] - 0s 442us/step - loss: 2.2859 - accuracy: 0.1255\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 385us/step - loss: 2.2860 - accuracy: 0.1267\n",
      "Epoch 157/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2857 - accuracy: 0.1340\n",
      "Epoch 158/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2856 - accuracy: 0.1322\n",
      "Epoch 159/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2859 - accuracy: 0.1286\n",
      "Epoch 160/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2854 - accuracy: 0.1304\n",
      "Epoch 161/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2851 - accuracy: 0.1286\n",
      "Epoch 162/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2852 - accuracy: 0.1383\n",
      "Epoch 163/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2850 - accuracy: 0.1286\n",
      "Epoch 164/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2847 - accuracy: 0.1280\n",
      "Epoch 165/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2848 - accuracy: 0.1310\n",
      "Epoch 166/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2847 - accuracy: 0.1280\n",
      "Epoch 167/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2843 - accuracy: 0.1346\n",
      "Epoch 168/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2844 - accuracy: 0.1352\n",
      "Epoch 169/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2843 - accuracy: 0.1334\n",
      "Epoch 170/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2840 - accuracy: 0.1413\n",
      "Epoch 171/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2838 - accuracy: 0.1280\n",
      "Epoch 172/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2841 - accuracy: 0.1286\n",
      "Epoch 173/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2838 - accuracy: 0.1322\n",
      "Epoch 174/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2836 - accuracy: 0.1316\n",
      "Epoch 175/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2836 - accuracy: 0.1352\n",
      "Epoch 176/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2833 - accuracy: 0.1328\n",
      "Epoch 177/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2834 - accuracy: 0.1322\n",
      "Epoch 178/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2831 - accuracy: 0.1310\n",
      "Epoch 179/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2830 - accuracy: 0.1352\n",
      "Epoch 180/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2828 - accuracy: 0.1358\n",
      "Epoch 181/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2827 - accuracy: 0.1292\n",
      "Epoch 182/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2824 - accuracy: 0.1377\n",
      "Epoch 183/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2828 - accuracy: 0.1231\n",
      "Epoch 184/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2823 - accuracy: 0.1273\n",
      "Epoch 185/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2824 - accuracy: 0.1316\n",
      "Epoch 186/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2819 - accuracy: 0.1364\n",
      "Epoch 187/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2821 - accuracy: 0.1371\n",
      "Epoch 188/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2819 - accuracy: 0.1310\n",
      "Epoch 189/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2818 - accuracy: 0.1261\n",
      "Epoch 190/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2816 - accuracy: 0.1231\n",
      "Epoch 191/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2817 - accuracy: 0.1358\n",
      "Epoch 192/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2811 - accuracy: 0.1255\n",
      "Epoch 193/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2814 - accuracy: 0.1322\n",
      "Epoch 194/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2813 - accuracy: 0.1237\n",
      "Epoch 195/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2809 - accuracy: 0.1371\n",
      "Epoch 196/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2808 - accuracy: 0.1334\n",
      "Epoch 197/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2807 - accuracy: 0.1298\n",
      "Epoch 198/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2809 - accuracy: 0.1340\n",
      "Epoch 199/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2805 - accuracy: 0.1273\n",
      "Epoch 200/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2805 - accuracy: 0.1310\n",
      "Epoch 201/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2803 - accuracy: 0.1255\n",
      "Epoch 202/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2805 - accuracy: 0.1292\n",
      "Epoch 203/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2797 - accuracy: 0.1358\n",
      "Epoch 204/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2798 - accuracy: 0.1334\n",
      "Epoch 205/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2795 - accuracy: 0.1298\n",
      "Epoch 206/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2799 - accuracy: 0.1322\n",
      "Epoch 207/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2795 - accuracy: 0.1310\n",
      "Epoch 208/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2795 - accuracy: 0.1310\n",
      "Epoch 209/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2796 - accuracy: 0.1261\n",
      "Epoch 210/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2791 - accuracy: 0.1267\n",
      "Epoch 211/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2796 - accuracy: 0.1298\n",
      "Epoch 212/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2791 - accuracy: 0.1298\n",
      "Epoch 213/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2790 - accuracy: 0.1243\n",
      "Epoch 214/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2789 - accuracy: 0.1401\n",
      "Epoch 215/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2787 - accuracy: 0.1340\n",
      "Epoch 216/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2787 - accuracy: 0.1346\n",
      "Epoch 217/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2789 - accuracy: 0.1340\n",
      "Epoch 218/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2786 - accuracy: 0.1328\n",
      "Epoch 219/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2782 - accuracy: 0.1364\n",
      "Epoch 220/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2780 - accuracy: 0.1334\n",
      "Epoch 221/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2783 - accuracy: 0.1286\n",
      "Epoch 222/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2781 - accuracy: 0.1304\n",
      "Epoch 223/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2775 - accuracy: 0.1322\n",
      "Epoch 224/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2776 - accuracy: 0.1358\n",
      "Epoch 225/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2780 - accuracy: 0.1371\n",
      "Epoch 226/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2777 - accuracy: 0.1389\n",
      "Epoch 227/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2777 - accuracy: 0.1340\n",
      "Epoch 228/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2770 - accuracy: 0.1280\n",
      "Epoch 229/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2773 - accuracy: 0.1340\n",
      "Epoch 230/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2774 - accuracy: 0.1292\n",
      "Epoch 231/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2771 - accuracy: 0.1298\n",
      "Epoch 232/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2774 - accuracy: 0.1377\n",
      "Epoch 233/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2773 - accuracy: 0.1358\n",
      "Epoch 234/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2770 - accuracy: 0.1322\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 385us/step - loss: 2.2773 - accuracy: 0.1316\n",
      "Epoch 236/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2768 - accuracy: 0.1267\n",
      "Epoch 237/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2770 - accuracy: 0.1431\n",
      "Epoch 238/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2763 - accuracy: 0.1395\n",
      "Epoch 239/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2764 - accuracy: 0.1407\n",
      "Epoch 240/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2765 - accuracy: 0.1401\n",
      "Epoch 241/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2761 - accuracy: 0.1340\n",
      "Epoch 242/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2765 - accuracy: 0.1286\n",
      "Epoch 243/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2763 - accuracy: 0.1322\n",
      "Epoch 244/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2763 - accuracy: 0.1328\n",
      "Epoch 245/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2762 - accuracy: 0.1389\n",
      "Epoch 246/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2760 - accuracy: 0.1328\n",
      "Epoch 247/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2752 - accuracy: 0.1413\n",
      "Epoch 248/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2758 - accuracy: 0.1334\n",
      "Epoch 249/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2764 - accuracy: 0.1298\n",
      "Epoch 250/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2760 - accuracy: 0.1334\n",
      "Epoch 251/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2755 - accuracy: 0.1443\n",
      "Epoch 252/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2760 - accuracy: 0.1310\n",
      "Epoch 253/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2758 - accuracy: 0.1358\n",
      "Epoch 254/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2757 - accuracy: 0.1383\n",
      "Epoch 255/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2753 - accuracy: 0.1395\n",
      "Epoch 256/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2752 - accuracy: 0.1383\n",
      "Epoch 257/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2757 - accuracy: 0.1401\n",
      "Epoch 258/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2750 - accuracy: 0.1322\n",
      "Epoch 259/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2752 - accuracy: 0.1340\n",
      "Epoch 260/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2747 - accuracy: 0.1389\n",
      "Epoch 261/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2752 - accuracy: 0.1316\n",
      "Epoch 262/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2746 - accuracy: 0.1419\n",
      "Epoch 263/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2752 - accuracy: 0.1316\n",
      "Epoch 264/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2748 - accuracy: 0.1383\n",
      "Epoch 265/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2752 - accuracy: 0.1407\n",
      "Epoch 266/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2746 - accuracy: 0.1358\n",
      "Epoch 267/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2743 - accuracy: 0.1389\n",
      "Epoch 268/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2745 - accuracy: 0.1401\n",
      "Epoch 269/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2745 - accuracy: 0.1377\n",
      "Epoch 270/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2744 - accuracy: 0.1334\n",
      "Epoch 271/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2738 - accuracy: 0.1401\n",
      "Epoch 272/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2737 - accuracy: 0.1407\n",
      "Epoch 273/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2748 - accuracy: 0.1292\n",
      "Epoch 274/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2740 - accuracy: 0.1383\n",
      "Epoch 275/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2739 - accuracy: 0.1328\n",
      "Epoch 276/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2741 - accuracy: 0.1340\n",
      "Epoch 277/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2736 - accuracy: 0.1364\n",
      "Epoch 278/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2738 - accuracy: 0.1401\n",
      "Epoch 279/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2740 - accuracy: 0.1340\n",
      "Epoch 280/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2734 - accuracy: 0.1352\n",
      "Epoch 281/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2735 - accuracy: 0.1401\n",
      "Epoch 282/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2736 - accuracy: 0.1371\n",
      "Epoch 283/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2737 - accuracy: 0.1316\n",
      "Epoch 284/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2729 - accuracy: 0.1419\n",
      "Epoch 285/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2730 - accuracy: 0.1310\n",
      "Epoch 286/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2726 - accuracy: 0.1407\n",
      "Epoch 287/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2734 - accuracy: 0.1407\n",
      "Epoch 288/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2733 - accuracy: 0.1377\n",
      "Epoch 289/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2733 - accuracy: 0.1383\n",
      "Epoch 290/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2730 - accuracy: 0.1340\n",
      "Epoch 291/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2730 - accuracy: 0.1449\n",
      "Epoch 292/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2729 - accuracy: 0.1304\n",
      "Epoch 293/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2731 - accuracy: 0.1310\n",
      "Epoch 294/500\n",
      "52/52 [==============================] - 0s 442us/step - loss: 2.2730 - accuracy: 0.1352\n",
      "Epoch 295/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2727 - accuracy: 0.1304\n",
      "Epoch 296/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2726 - accuracy: 0.1286\n",
      "Epoch 297/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2721 - accuracy: 0.1443\n",
      "Epoch 298/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2724 - accuracy: 0.1468\n",
      "Epoch 299/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2725 - accuracy: 0.1383\n",
      "Epoch 300/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2721 - accuracy: 0.1377\n",
      "Epoch 301/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2724 - accuracy: 0.1395\n",
      "Epoch 302/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2723 - accuracy: 0.1346\n",
      "Epoch 303/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2720 - accuracy: 0.1371\n",
      "Epoch 304/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2716 - accuracy: 0.1395\n",
      "Epoch 305/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2724 - accuracy: 0.1322\n",
      "Epoch 306/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2722 - accuracy: 0.1395\n",
      "Epoch 307/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2722 - accuracy: 0.1340\n",
      "Epoch 308/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2719 - accuracy: 0.1425\n",
      "Epoch 309/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2720 - accuracy: 0.1407\n",
      "Epoch 310/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2723 - accuracy: 0.1437\n",
      "Epoch 311/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2719 - accuracy: 0.1401\n",
      "Epoch 312/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2721 - accuracy: 0.1358\n",
      "Epoch 313/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2717 - accuracy: 0.1401\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 385us/step - loss: 2.2716 - accuracy: 0.1346\n",
      "Epoch 315/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2712 - accuracy: 0.1425\n",
      "Epoch 316/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2720 - accuracy: 0.1401\n",
      "Epoch 317/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2720 - accuracy: 0.1352\n",
      "Epoch 318/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2716 - accuracy: 0.1340\n",
      "Epoch 319/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2712 - accuracy: 0.1431\n",
      "Epoch 320/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2715 - accuracy: 0.1389\n",
      "Epoch 321/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2712 - accuracy: 0.1407\n",
      "Epoch 322/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2719 - accuracy: 0.1340\n",
      "Epoch 323/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2709 - accuracy: 0.1407\n",
      "Epoch 324/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2716 - accuracy: 0.1383\n",
      "Epoch 325/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2714 - accuracy: 0.1431\n",
      "Epoch 326/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2715 - accuracy: 0.1389\n",
      "Epoch 327/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2711 - accuracy: 0.1407\n",
      "Epoch 328/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2708 - accuracy: 0.1364\n",
      "Epoch 329/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2710 - accuracy: 0.1407\n",
      "Epoch 330/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2712 - accuracy: 0.1437\n",
      "Epoch 331/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2708 - accuracy: 0.1395\n",
      "Epoch 332/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2708 - accuracy: 0.1455\n",
      "Epoch 333/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2711 - accuracy: 0.1395\n",
      "Epoch 334/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2704 - accuracy: 0.1364\n",
      "Epoch 335/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2703 - accuracy: 0.1480\n",
      "Epoch 336/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2706 - accuracy: 0.1364\n",
      "Epoch 337/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2700 - accuracy: 0.1395\n",
      "Epoch 338/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2708 - accuracy: 0.1419\n",
      "Epoch 339/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2701 - accuracy: 0.1425\n",
      "Epoch 340/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2707 - accuracy: 0.1419\n",
      "Epoch 341/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2702 - accuracy: 0.1449\n",
      "Epoch 342/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2705 - accuracy: 0.1358\n",
      "Epoch 343/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2701 - accuracy: 0.1419\n",
      "Epoch 344/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2699 - accuracy: 0.1425\n",
      "Epoch 345/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2705 - accuracy: 0.1364\n",
      "Epoch 346/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2703 - accuracy: 0.1273\n",
      "Epoch 347/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2700 - accuracy: 0.1304\n",
      "Epoch 348/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2698 - accuracy: 0.1407\n",
      "Epoch 349/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2701 - accuracy: 0.1383\n",
      "Epoch 350/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2697 - accuracy: 0.1346\n",
      "Epoch 351/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2702 - accuracy: 0.1401\n",
      "Epoch 352/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2695 - accuracy: 0.1352\n",
      "Epoch 353/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2704 - accuracy: 0.1267\n",
      "Epoch 354/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2703 - accuracy: 0.1377\n",
      "Epoch 355/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2697 - accuracy: 0.1364\n",
      "Epoch 356/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2696 - accuracy: 0.1431\n",
      "Epoch 357/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2695 - accuracy: 0.1443\n",
      "Epoch 358/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2689 - accuracy: 0.1419\n",
      "Epoch 359/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2694 - accuracy: 0.1395\n",
      "Epoch 360/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2695 - accuracy: 0.1455\n",
      "Epoch 361/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2696 - accuracy: 0.1407\n",
      "Epoch 362/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2697 - accuracy: 0.1425\n",
      "Epoch 363/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2690 - accuracy: 0.1334\n",
      "Epoch 364/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2687 - accuracy: 0.1419\n",
      "Epoch 365/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2692 - accuracy: 0.1358\n",
      "Epoch 366/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2701 - accuracy: 0.1407\n",
      "Epoch 367/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2696 - accuracy: 0.1371\n",
      "Epoch 368/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2692 - accuracy: 0.1431\n",
      "Epoch 369/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2697 - accuracy: 0.1346\n",
      "Epoch 370/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2684 - accuracy: 0.1395\n",
      "Epoch 371/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2694 - accuracy: 0.1340\n",
      "Epoch 372/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2686 - accuracy: 0.1425\n",
      "Epoch 373/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2686 - accuracy: 0.1449\n",
      "Epoch 374/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2691 - accuracy: 0.1431\n",
      "Epoch 375/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2686 - accuracy: 0.1401\n",
      "Epoch 376/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2687 - accuracy: 0.1346\n",
      "Epoch 377/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2690 - accuracy: 0.1437\n",
      "Epoch 378/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2688 - accuracy: 0.1419\n",
      "Epoch 379/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2686 - accuracy: 0.1516\n",
      "Epoch 380/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2689 - accuracy: 0.1443\n",
      "Epoch 381/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2685 - accuracy: 0.1358\n",
      "Epoch 382/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2685 - accuracy: 0.1443\n",
      "Epoch 383/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2686 - accuracy: 0.1346\n",
      "Epoch 384/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2693 - accuracy: 0.1431\n",
      "Epoch 385/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2689 - accuracy: 0.1401\n",
      "Epoch 386/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2683 - accuracy: 0.1431\n",
      "Epoch 387/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2687 - accuracy: 0.1316\n",
      "Epoch 388/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2680 - accuracy: 0.1364\n",
      "Epoch 389/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2688 - accuracy: 0.1419\n",
      "Epoch 390/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2686 - accuracy: 0.1358\n",
      "Epoch 391/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2681 - accuracy: 0.1334\n",
      "Epoch 392/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2677 - accuracy: 0.1340\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 385us/step - loss: 2.2680 - accuracy: 0.1480\n",
      "Epoch 394/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2675 - accuracy: 0.1364\n",
      "Epoch 395/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2687 - accuracy: 0.1474\n",
      "Epoch 396/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2683 - accuracy: 0.1364\n",
      "Epoch 397/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2672 - accuracy: 0.1468\n",
      "Epoch 398/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2682 - accuracy: 0.1286\n",
      "Epoch 399/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2680 - accuracy: 0.1358\n",
      "Epoch 400/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2679 - accuracy: 0.1395\n",
      "Epoch 401/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2678 - accuracy: 0.1437\n",
      "Epoch 402/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2680 - accuracy: 0.1468\n",
      "Epoch 403/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2684 - accuracy: 0.1419\n",
      "Epoch 404/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2684 - accuracy: 0.1383\n",
      "Epoch 405/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2677 - accuracy: 0.1516\n",
      "Epoch 406/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2676 - accuracy: 0.1431\n",
      "Epoch 407/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2668 - accuracy: 0.1534\n",
      "Epoch 408/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2677 - accuracy: 0.1383\n",
      "Epoch 409/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2668 - accuracy: 0.1383\n",
      "Epoch 410/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2678 - accuracy: 0.1322\n",
      "Epoch 411/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2675 - accuracy: 0.1522\n",
      "Epoch 412/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2671 - accuracy: 0.1425\n",
      "Epoch 413/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2675 - accuracy: 0.1389\n",
      "Epoch 414/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2673 - accuracy: 0.1401\n",
      "Epoch 415/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2675 - accuracy: 0.1443\n",
      "Epoch 416/500\n",
      "52/52 [==============================] - 0s 386us/step - loss: 2.2674 - accuracy: 0.1407\n",
      "Epoch 417/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2675 - accuracy: 0.1425\n",
      "Epoch 418/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2677 - accuracy: 0.1383\n",
      "Epoch 419/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2662 - accuracy: 0.1358\n",
      "Epoch 420/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2678 - accuracy: 0.1431\n",
      "Epoch 421/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2659 - accuracy: 0.1419\n",
      "Epoch 422/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2672 - accuracy: 0.1413\n",
      "Epoch 423/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2665 - accuracy: 0.1437\n",
      "Epoch 424/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2669 - accuracy: 0.1461\n",
      "Epoch 425/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2671 - accuracy: 0.1474\n",
      "Epoch 426/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2679 - accuracy: 0.1534\n",
      "Epoch 427/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2660 - accuracy: 0.1383\n",
      "Epoch 428/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2671 - accuracy: 0.1340\n",
      "Epoch 429/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2659 - accuracy: 0.1413\n",
      "Epoch 430/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2669 - accuracy: 0.1395\n",
      "Epoch 431/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2667 - accuracy: 0.1395\n",
      "Epoch 432/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2664 - accuracy: 0.1413\n",
      "Epoch 433/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2669 - accuracy: 0.1401\n",
      "Epoch 434/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2662 - accuracy: 0.1322\n",
      "Epoch 435/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2665 - accuracy: 0.1516\n",
      "Epoch 436/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2665 - accuracy: 0.1480\n",
      "Epoch 437/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2663 - accuracy: 0.1449\n",
      "Epoch 438/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2659 - accuracy: 0.1395\n",
      "Epoch 439/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2668 - accuracy: 0.1449\n",
      "Epoch 440/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2655 - accuracy: 0.1413\n",
      "Epoch 441/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2665 - accuracy: 0.1431\n",
      "Epoch 442/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2660 - accuracy: 0.1437\n",
      "Epoch 443/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2667 - accuracy: 0.1474\n",
      "Epoch 444/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2666 - accuracy: 0.1425\n",
      "Epoch 445/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2661 - accuracy: 0.1425\n",
      "Epoch 446/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2656 - accuracy: 0.1461\n",
      "Epoch 447/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2663 - accuracy: 0.1413\n",
      "Epoch 448/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2666 - accuracy: 0.1431\n",
      "Epoch 449/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2656 - accuracy: 0.1419\n",
      "Epoch 450/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2658 - accuracy: 0.1407\n",
      "Epoch 451/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2654 - accuracy: 0.1443\n",
      "Epoch 452/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2662 - accuracy: 0.1389\n",
      "Epoch 453/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2657 - accuracy: 0.1340\n",
      "Epoch 454/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2653 - accuracy: 0.1461\n",
      "Epoch 455/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2649 - accuracy: 0.1449\n",
      "Epoch 456/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2659 - accuracy: 0.1474\n",
      "Epoch 457/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2656 - accuracy: 0.1443\n",
      "Epoch 458/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2662 - accuracy: 0.1443\n",
      "Epoch 459/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2647 - accuracy: 0.1528\n",
      "Epoch 460/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2652 - accuracy: 0.1377\n",
      "Epoch 461/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2653 - accuracy: 0.1431\n",
      "Epoch 462/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2650 - accuracy: 0.1468\n",
      "Epoch 463/500\n",
      "52/52 [==============================] - 0s 596us/step - loss: 2.2649 - accuracy: 0.1516\n",
      "Epoch 464/500\n",
      "52/52 [==============================] - 0s 423us/step - loss: 2.2653 - accuracy: 0.1383\n",
      "Epoch 465/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2646 - accuracy: 0.1492\n",
      "Epoch 466/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2650 - accuracy: 0.1407\n",
      "Epoch 467/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2649 - accuracy: 0.1449\n",
      "Epoch 468/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2651 - accuracy: 0.1498\n",
      "Epoch 469/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2651 - accuracy: 0.1425\n",
      "Epoch 470/500\n",
      "52/52 [==============================] - 0s 404us/step - loss: 2.2650 - accuracy: 0.1371\n",
      "Epoch 471/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2645 - accuracy: 0.1437\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 365us/step - loss: 2.2649 - accuracy: 0.1522\n",
      "Epoch 473/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2648 - accuracy: 0.1461\n",
      "Epoch 474/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2645 - accuracy: 0.1534\n",
      "Epoch 475/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2648 - accuracy: 0.1389\n",
      "Epoch 476/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2652 - accuracy: 0.1534\n",
      "Epoch 477/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2653 - accuracy: 0.1443\n",
      "Epoch 478/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2651 - accuracy: 0.1474\n",
      "Epoch 479/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2642 - accuracy: 0.1455\n",
      "Epoch 480/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2651 - accuracy: 0.1455\n",
      "Epoch 481/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2639 - accuracy: 0.1546\n",
      "Epoch 482/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2642 - accuracy: 0.1389\n",
      "Epoch 483/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2638 - accuracy: 0.1419\n",
      "Epoch 484/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2647 - accuracy: 0.1449\n",
      "Epoch 485/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2644 - accuracy: 0.1486\n",
      "Epoch 486/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2646 - accuracy: 0.1413\n",
      "Epoch 487/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2644 - accuracy: 0.1522\n",
      "Epoch 488/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2648 - accuracy: 0.1468\n",
      "Epoch 489/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2638 - accuracy: 0.1431\n",
      "Epoch 490/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2634 - accuracy: 0.1437\n",
      "Epoch 491/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2635 - accuracy: 0.1401\n",
      "Epoch 492/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2643 - accuracy: 0.1437\n",
      "Epoch 493/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2635 - accuracy: 0.1413\n",
      "Epoch 494/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2627 - accuracy: 0.1449\n",
      "Epoch 495/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2641 - accuracy: 0.1443\n",
      "Epoch 496/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2641 - accuracy: 0.1443\n",
      "Epoch 497/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2643 - accuracy: 0.1455\n",
      "Epoch 498/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2639 - accuracy: 0.1364\n",
      "Epoch 499/500\n",
      "52/52 [==============================] - 0s 385us/step - loss: 2.2644 - accuracy: 0.1413\n",
      "Epoch 500/500\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.2635 - accuracy: 0.1528\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train_categorical,\n",
    "  epochs=500,\n",
    "  batch_size=32,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "211c877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 3) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f428cbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input Tensor(\"flatten_input:0\", shape=(None, 8, 8), dtype=float32), but it was called on an input with incompatible shape (None, 64).\n",
      "13/13 [==============================] - 0s 385us/step - loss: 2.2842 - accuracy: 0.1065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.284184455871582, 0.10653752833604813]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate\n",
    "model.evaluate(\n",
    "  x_test,\n",
    "  to_categorical(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b03a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(413,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e07621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8, 8) for input Tensor(\"flatten_input:0\", shape=(None, 8, 8), dtype=float32), but it was called on an input with incompatible shape (None, 64).\n",
      "[[0.13812155 0.12008146 0.09773754 0.08165742 0.10373622 0.06528758\n",
      "  0.10184798 0.12269851 0.09334105 0.07549064]\n",
      " [0.04840153 0.05378013 0.08266235 0.10773489 0.11915726 0.12323114\n",
      "  0.12840798 0.10456369 0.10130878 0.13075234]\n",
      " [0.13629302 0.13263698 0.09682776 0.08965857 0.09721289 0.08327985\n",
      "  0.09238733 0.11266457 0.09167794 0.06736103]\n",
      " [0.15731208 0.13600793 0.09792562 0.08209153 0.09756866 0.06415804\n",
      "  0.09126976 0.11725233 0.0900999  0.06631414]\n",
      " [0.09186681 0.09055873 0.07157511 0.06832685 0.11622792 0.06250652\n",
      "  0.14436387 0.14363028 0.11030938 0.10063453]\n",
      " [0.06370009 0.06649297 0.09956017 0.12913159 0.10705756 0.13465561\n",
      "  0.09496424 0.08738829 0.10203282 0.11501671]\n",
      " [0.1451714  0.13254844 0.10324281 0.09020007 0.09586038 0.07786156\n",
      "  0.08779937 0.10772026 0.09158933 0.06800642]\n",
      " [0.0827639  0.08634948 0.09544757 0.10546533 0.11049236 0.10685403\n",
      "  0.10668921 0.10451846 0.10193623 0.09948339]\n",
      " [0.16831906 0.1488481  0.1094984  0.09324595 0.08827821 0.07660218\n",
      "  0.07332406 0.09856123 0.08471163 0.05861114]]\n",
      "[0 9 0 0 6 5 0 4 0]\n",
      "Check the truth\n",
      "1303    6\n",
      "2027    9\n",
      "693     3\n",
      "1914    9\n",
      "29      0\n",
      "1094    5\n",
      "1680    8\n",
      "453     2\n",
      "1117    5\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(x_test[0:9])\n",
    "print(predictions)\n",
    "\n",
    "print(np.argmax(predictions, axis=1))\n",
    "\n",
    "print(\"Check the truth\")\n",
    "print(y_test[0:9]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e9215",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6e9cfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finsihed reading data\n",
      "(2062, 64, 64)\n",
      "(2062,)\n"
     ]
    }
   ],
   "source": [
    "orig_X = np.load('X.npy')\n",
    "orig_Y = np.load('Y.npy')\n",
    "print('finsihed reading data')\n",
    "print(orig_X.shape)\n",
    "print(orig_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa365b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_Y= np.argmax(orig_Y, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a041f493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1649, 64, 64)\n",
      "(1649,)\n",
      "(413, 64, 64)\n",
      "(413,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(orig_X,orig_Y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f18d5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1649, 64*64)\n",
    "X_test = X_test.reshape(413, 64*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8c5b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihsan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f79cefc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihsan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", max_iter=100)\n",
    "softmax_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4a445de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7530266343825666\n",
      "0.9957550030321407\n"
     ]
    }
   ],
   "source": [
    "print( softmax_reg.score(X_test, Y_test) )\n",
    "print( softmax_reg.score(X_train, Y_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03185cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7530266343825666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = softmax_reg.predict(X_test)\n",
    "accVal = accuracy_score(Y_test, y_pred)\n",
    "print(accVal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
